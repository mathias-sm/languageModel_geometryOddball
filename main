#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""Model runner for the oddball cognition

Usage:
  main run <jnd_length> <jnd_angle> <jnd_direction> <angle_baseline_a> <angle_baseline_d>
  main show <optimized_dump>
  main search
  main (-h | --help)

Options:
  -h --help     Show this screen.
"""
from docopt import docopt


"""A file to simulate the two models Stan and I have
"""

import pickle
import json
import random
import string
import material
import math
import numpy as np
import collections
import model1
import model2
import csv
import itertools

import copy
import inspect

from skopt import Optimizer, dump, Space
from skopt.learning import GaussianProcessRegressor
from skopt.learning.gaussian_process.kernels import Matern
from skopt.space import Real
from sklearn.externals.joblib import Parallel, delayed

import matplotlib.pyplot as plt
from skopt.plots import plot_objective, plot_evaluations

# Precompute things for faster execution
observable_data = material.pre_compute()
# Load the ref data from french
ref = np.empty(11)
i = 0
with open('french_small.csv', 'r') as csvfile:
    spamreader = csv.reader(csvfile, delimiter=',')
    for row in spamreader:
      ref[i] = float(row[1])
      i += 1


def run(subject_jnd_l = 1, subject_jnd_a = 1, subject_jnd_d = 1, angle_baseline_a=0.7, angle_baseline_d=0.7):
  num_repetition = 1000
  success = np.empty(11)
  i = 0
  for name, observed in observable_data.items():
    tmp = []
    def process(t):
      results = []
      for j in range(num_repetition):
        results.append(model1.model(observed[t[0]],
                                    observed[t[1]],
                                    subject_jnd_l,
                                    subject_jnd_a,
                                    subject_jnd_d,
                                    angle_baseline_a,
                                    angle_baseline_d))
      return results
    tmp = []
    for t in [(0,1), (0,2), (0,3), (0,4), (1,0), (2,0), (3,0), (4,0)]:
        tmp.append(process(t))
    success[i] = np.mean(tmp)
    i += 1
  return success

def show_optimized(optimized):
  p1 = plot_objective(optimized)
  p2 = plot_evaluations(optimized)
  plt.set_cmap("viridis")
  plt.grid()
  plt.legend()
  plt.show()


def search():

  def processInput(t):
    x0,x1,x2,x3,x4 = t
    r = run(x0,x1,x2,x3,x4)
    new = np.sum((r-ref)**2)
    print("f({},{},{},{},{}) = {}".format(x0,x1,x2,x3,x4, new))
    return new
  
  optimizer = Optimizer(
      dimensions=[(0.0,2.0), (0.0,2.0), (0.0,2.0), (0.0,1.0), (0.0,1.0)],
      n_initial_points=320 # For a good-ish global estimation
  )

  result = None
  for i in range(20): 
    print("Inner {}/20".format(i+1))
    x = optimizer.ask(n_points=32)
    y = Parallel(n_jobs=32)(delayed(processInput)(t) for t in x)
    result = optimizer.tell(x, y)
    result.specs = {'args': {}, 'function': {}} # Dummy specs, never useful
    dump(result, "partial_{}.dump.gz".format(i), store_objective=False, compress=9)

  dump(result, "full_run.dump", store_objective=False, compress=9)
  show_optimized(result)

if __name__ == "__main__":
  arguments = docopt(__doc__, version='0.0.1')
  if arguments["search"]:
    search()
  elif arguments["run"]:
    r = run(float(arguments["<jnd_length>"]),
            float(arguments["<jnd_angle>"]),
            float(arguments["<jnd_direction>"]),
            float(arguments["<angle_baseline_a>"]),
            float(arguments["<angle_baseline_d>"]))
    print(np.sum((r-ref)**2))
    r = np.ndarray.tolist(r)
    with open('result.json', 'w') as fp:
      json.dump(r, fp)
  elif arguments["show"]:
    optimized = load(arguments["<optimized_dump>"])
    show_optimized(optimized)
