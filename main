#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Model runner for the oddball cognition

Can either run a single simulation, search in some space of parameters, or
display the results of a finished past search dumped to disk.

Usage:
  main run [options]
  main search <n_trials_random> <n_trials_total> [options]
  main show <optimized_dump> [--output=FILE]
  main (-h | --help)

Options:
  --model=<l>    Model to use [default: 1]
  --reps=<n>     Model to use [default: 250]
  --params FILE  File containing the parameters (JSON) to use [default: parameters.json]
  -h --help      Show this screen.
"""

# Documentation
from docopt import docopt

# From this project
import material
import display_results

# Other
import csv
import json
import psutil
import tqdm
import importlib
import numpy as np

from skopt import Optimizer, dump, load
from sklearn.externals.joblib import Parallel, delayed

def init_obs():
    """ Pre-computes useful stuff to be used everywhere from the material
    """
    return material.pre_compute()

def init_ref():
    """ Pre-loads the reference data from behavioural experiment
    """
    reference_data = np.empty(11)
    i = 0
    with open('behavioural_data/french_small.csv', 'r') as csvfile:
        spamreader = csv.reader(csvfile, delimiter=',')
        for row in spamreader:
            reference_data[i] = float(row[1])
            i += 1
    return reference_data

def run(parameters,
        repetitions_per_run = 250,
        parallel = False):
    """ Forward run of a simulation given parameters

    Given a set of parameters *for a subject* simulates all shapes a certain
    amount of time and return a summary of the results

    parameters: float tuple
                A list of parameters to give to the model
    repetitions_per_run: int
                         How many times should we sample before averaging
    parallel: bool
              Whether the run should try to parallelize over shapes

    Returns
    -------
    np.array(int) of size 11
        Mean success rate for each of the 11 shapes after simulation.
    """

    observable_data = init_obs()
    success = []

    # Function to process a single shape
    def processShape(s):
        name, observed = s
        def process(t):
            results = []
            for j in range(repetitions_per_run):
                results.append(model.model(observed[t[0]],
                                           observed[t[1]],
                                           parameters))
            return results
        tmp = []
        conditions = [(0,1), (0,2), (0,3), (0,4), (1,0), (2,0), (3,0), (4,0)]
        for t in conditions:
            tmp.append(process(t))
        return np.mean(tmp[0:3]), np.mean(tmp[4:7])

    # Map over the possible shapes the previous function
    if parallel:
        n_cpus = psutil.cpu_count()
        success = Parallel(n_jobs=n_cpus)(delayed(processShape)(s) for s in observable_data.items())
    else:
        for s in observable_data.items():
            success.append(processShape(s))

    return success


def search(n_trials_total = 640,
           n_trials_random = 320,
           repetitions_per_run = 250,
           model = 1):
    """ Search the best parameters in some space

    The args dictate how many simulation should be run, as well as
    how precise each simulation should be.
    
    n_trials_total:  int
                     How many points should be tried in total
    n_trials_random: int
                     Out of those, how many should be sampled randomly and
                     uniformly?
    repetitions_per_run: int
                         Each simulation is itself the mean of repeated draws,
                         how many such repeated draws should be use (higher ->
                         more precise but longer)
    

    Returns
    -------
    nothing
        Sides effect include:
        * Writing the results to disk, as well as intermediary steps in case of
          failure or early stopping
        * Calling the visualisation function on the results, whatever that
          function does
    """

    # Pre-load behavioural data
    reference_data = init_ref()

    # Assert input makes sense
    assert(n_trials_random <= n_trials_total)

    # Function to process a single set of parameters
    def processInput(parameters):
        r = run(parameters,
                repetitions_per_run,
                parallel=False)
        r = np.array(np.mean(r,1))
        new = np.sum((r-reference_data)**2)
        return new

    # Initialize the optimizer with the search bounds as well as the amount of
    # random points to try
    optimizer = None
    if model == 1:
        optimizer = Optimizer(
            dimensions=[(0.0,1.0)],
            n_initial_points=n_trials_random
        )
    elif model == 2:
        optimizer = Optimizer(
            dimensions=[(0.0,1.0), (0.0,1.0)],
            n_initial_points=n_trials_random
        )
    elif model == 3:
        optimizer = Optimizer(
            dimensions=[(0.0,1.0), (0.0,1.0)],
            n_initial_points=n_trials_random
        )
    elif model == 4:
        optimizer = Optimizer(
            dimensions=[(0.0,1.0), (0.0,1.0), (0.0,1.0), (0.0,1.0), (0.0,1.0),
                (0.0,1.0)],
            n_initial_points=n_trials_random
        )
    elif model == 5:
        optimizer = Optimizer(
            dimensions=[(0.0,5.0), (0.0,5.0), (0.0,5.0), (0.0,5.0), (0.0,5.0), (0., 50.), (0.,50.), (0.,50.)],
            n_initial_points=n_trials_random
        )

    # Determine how much we can parallelize and adjust loops accorgingly
    n_cpus = psutil.cpu_count()
    loop_size = round(n_trials_total / n_cpus)

    result = None
    for i in tqdm.tqdm(range(loop_size)):
        # Ask the optimizer which points we should focus on
        x = optimizer.ask(n_points=n_cpus)
        # Parallelize the computation for this set of points
        y = Parallel(n_jobs=n_cpus)(delayed(processInput)(t) for t in x)
        # Tell the optimizer the results for next round
        result = optimizer.tell(x, y)
        result.specs = {'args': {}, 'function': {}} # Dummy specs, never useful
        dump(result, "partial_{}.dump.gz".format(i), store_objective=False, compress=9)

    dump(result, "full_run.dump.gz", store_objective=False, compress=9)
    display_results.show_optimized(result)

if __name__ == "__main__":
    """ Parse args and call relevant functions â€” or die trying
    """

    args = docopt(__doc__, version='0.0.1')

    # Oh, look, a dynamic loading based on a str concatenated with an arg...!
    model = importlib.import_module("model"+args["--model"])

    if args["search"]:
        search(int(args["<n_trials_total>"]),
               int(args["<n_trials_random>"]),
               int(args["--reps"]),
               int(args["--model"]))

    elif args["run"]:
        # Loads the model's parameters from the relevant file and CLI args
        num_rep = int(args["--reps"])
        params = json.loads(open(args["--params"]).read())
        parameters = []
        model_n = int(args["--model"])
        if model_n == 1:
            parameters = [params["jnd_length"]]
        elif model_n == 2:
            parameters = [params["jnd_angle"], params["angle_baseline_a"]]
        elif model_n == 3:
            parameters = [params["jnd_direction"], params["angle_baseline_d"]]
        elif model_n == 4:
            parameters = [params["jnd_length"],
                          params["jnd_angle"], params["angle_baseline_a"],
                          params["jnd_direction"], params["angle_baseline_d"]]
        elif model_n == 5:
            assert(False)


        # Run said model
        r = run(parameters, num_rep, parallel=False)

        # Output the metric for quick feedback
        reference_data = init_ref()
        print(np.sum((np.mean(r,1)-reference_data)**2))

        # Saves the detailed averages to the csv file
        with open('results.csv', 'w', newline='') as csvfile:
            spamwriter = csv.writer(csvfile, delimiter=',')
            spamwriter.writerow(["shape", "mean", "mostlyRegularShapes", "num_rep"])
            i = 0
            for name, _ in material.allShapes.items():
                spamwriter.writerow([name, r[i][0], True,num_rep])
                spamwriter.writerow([name, r[i][1], False,num_rep])
                i += 1

    elif args["show"]:
        optimized = load(args["<optimized_dump>"])
        display_results.show_optimized(optimized, args["--output"])
    else:
        print("I died trying. Docopt shouldn't allow this though.")
